{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOSHWIN ISAC\\AppData\\Local\\Temp\\ipykernel_19172\\2714595723.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "path = \"D:\\\\dataset for lab programs\\\\TB_Chest_Radiography_Database\"\n",
    "classes = {'Normal': 0, 'Tuberculosis': 1}\n",
    "def preprocess_images(path, classes):\n",
    "    x ,y =[],[]\n",
    "    for key in classes:\n",
    "        pth = os.path.join(path, key)\n",
    "        for i in os.listdir(pth):\n",
    "            img = cv2.imread(os.path.join(pth, i), 0)\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            img = cv2.normalize(img, None, 0, 1, cv2.NORM_MINMAX)\n",
    "            x.append(img.flatten())\n",
    "            y.append(classes[key])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x, y = preprocess_images(path, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "0    3500\n",
      "1     700\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = pd.Series(y).value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Data augmentation\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Stratified K-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store model evaluation scores\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training data into train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Oversample the minority class in the training set if needed\n",
    "oversample = RandomOverSampler()\n",
    "x_train_resampled, y_train_resampled = oversample.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution after sampling:\n",
      "0    2236\n",
      "1    2236\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution check after sampling\n",
    "class_counts_sampled = pd.Series(y_train_resampled).value_counts()\n",
    "print(\"\\nClass Distribution after sampling:\")\n",
    "print(class_counts_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom CNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "\n",
    "shape=(224,224,3)\n",
    "num_classes=2\n",
    "\n",
    "model1=Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(BatchNormalization())\n",
    "# convolutional layer\n",
    "model1.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(BatchNormalization())\n",
    "\n",
    "model1.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(BatchNormalization())\n",
    "\n",
    "model1.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model1.add(BatchNormalization())\n",
    "# flatten output of conv\n",
    "model1.add(Flatten())\n",
    "\n",
    "# hidden layer\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(512, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
