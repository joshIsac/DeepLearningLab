{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI0B2VVofK876krq5HO5Fw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshIsac/DeepLearningLab/blob/main/2348523_Excercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Define derivative of sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "  return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "\n",
        "# Initialize weights and biases\n",
        "w1=w2 = 1\n",
        "b1= b2=-0.5\n",
        "\n",
        "# Define learning rate under the assumption that let us consider taking\n",
        "lr = 0.1\n",
        "\n",
        "# Define input and target output\n",
        "x = 0.5\n",
        "y = 1\n",
        "\n",
        "# Forward pass\n",
        "h1_in = x * w1 + b1\n",
        "print(h1_in)\n",
        "h1_out = sigmoid(h1_in)\n",
        "print(h1_out)\n",
        "\n",
        "#input of h2\n",
        "h2_in = h1_out * w2 + b2\n",
        "print(h2_in)\n",
        "h2_out = sigmoid(h2_in)\n",
        "print(h2_out)\n",
        "\n",
        "output = h2_out\n",
        "print(output)\n",
        "\n",
        "\n",
        "# Compute error\n",
        "error = (1/2)* (y - output) ** 2\n",
        "\n",
        "# Backpropagation\n",
        "delta_output = (output - y) * sigmoid_derivative(output)\n",
        "delta_h2 = delta_output * w2 * sigmoid_derivative(h2_out)\n",
        "delta_h1 = delta_h2 * w1 * sigmoid_derivative(h1_out)\n",
        "\n",
        "# Update weights and biases\n",
        "w1 -= lr * delta_h1 * x\n",
        "w2 -= lr * delta_h2 * h1_out\n",
        "b1 -= lr * delta_h1\n",
        "b2 -= lr * delta_h2\n",
        "\n",
        "# Forward pass after first iteration\n",
        "h1_in = x * w1 + b1\n",
        "h1_out = sigmoid(h1_in)\n",
        "\n",
        "h2_in = h1_out * w2 + b2\n",
        "h2_out = sigmoid(h2_in)\n",
        "\n",
        "output = h2_out\n",
        "\n",
        "# Print results\n",
        "print(\"Forward pass output after 1st iteration:\", output)\n",
        "\n",
        "# Forward pass after second iteration (repeating the same process)\n",
        "del_output = (output -y) * sigmoid_derivative(output)\n",
        "delta_h2 = delta_output * w2 * sigmoid_derivative(h2_out)\n",
        "delta_h1 = delta_h2 * w1 * sigmoid_derivative(h1_out)\n",
        "\n",
        "w1 -= lr * delta_h1 * x\n",
        "w2 -= lr * delta_h2 * h1_out\n",
        "b1 -= lr * delta_h1\n",
        "b2 -= lr * delta_h2\n",
        "\n",
        "h1_in = x * w1 + b1\n",
        "h1_out = sigmoid(h1_in)\n",
        "\n",
        "h2_in = h1_out * w2 + b2\n",
        "h2_out = sigmoid(h2_in)\n",
        "\n",
        "output = h2_out\n",
        "\n",
        "# Print results after 2 iterations\n",
        "print(\"Forward pass output after 2nd iteration:\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em4kmp_FwF7p",
        "outputId": "ecf2ff9e-b451-4976-9ac4-04b51177f96c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.5\n",
            "0.0\n",
            "0.5\n",
            "0.5\n",
            "Forward pass output after 1st iteration: 0.5009136840896408\n",
            "Forward pass output after 2nd iteration: 0.5018286429916783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define input vector and bias\n",
        "X = np.array([1, 2, 2, 1])\n",
        "bias = 0\n",
        "\n",
        "# Define learned parameter vector W\n",
        "W = np.array([0.25, 0.25, 0.25, 0.25])\n",
        "\n",
        "# Define target output\n",
        "target = 2\n",
        "\n",
        "# Calculate output without activation function\n",
        "output = np.dot(X, W) + bias\n",
        "\n",
        "# Calculate loss without regularization\n",
        "loss = 0.5 * (output - target) ** 2\n",
        "\n",
        "# L1 regularization\n",
        "l1_lambda = 0.1\n",
        "l1_regularization = l1_lambda * np.sum(np.abs(W))\n",
        "total_loss_l1 = loss + l1_regularization\n",
        "\n",
        "# L2 regularization\n",
        "l2_lambda = 0.1\n",
        "l2_regularization = 0.5 * l2_lambda * np.sum(W ** 2)\n",
        "total_loss_l2 = loss + l2_regularization\n",
        "\n",
        "# Elastic Net regularization\n",
        "elastic_lambda = 0.1\n",
        "elastic_alpha = 0.5  # mixing parameter, 0 for L2, 1 for L1\n",
        "elastic_regularization = (elastic_alpha * l1_regularization) + ((1 - elastic_alpha) * l2_regularization)\n",
        "total_loss_elastic = loss + elastic_regularization\n",
        "\n",
        "# Compare effects of regularization techniques\n",
        "print(\"Total Loss without regularization:\", loss)\n",
        "print(\"Total Loss with L1 regularization:\", total_loss_l1)\n",
        "print(\"Total Loss with L2 regularization:\", total_loss_l2)\n",
        "print(\"Total Loss with Elastic Net regularization:\", total_loss_elastic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQjuRk-bwiT4",
        "outputId": "01337a75-c325-400e-f2ec-25364c3b52e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Loss without regularization: 0.125\n",
            "Total Loss with L1 regularization: 0.225\n",
            "Total Loss with L2 regularization: 0.1375\n",
            "Total Loss with Elastic Net regularization: 0.18125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4rt8n7bwvCD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}