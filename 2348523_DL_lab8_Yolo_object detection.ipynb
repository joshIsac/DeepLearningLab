{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed =40\n",
    "np.random.seed(40)\n",
    "tf.random.set_seed(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "labels_path = \"D:\\\\dataset for lab programs\\\\labels_traffic-data\"\n",
    "images_path = \"D:\\\\dataset for lab programs\\\\traffic data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "image_files = [f for f in os.listdir(images_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "label_files = [f for f in os.listdir(labels_path) if f.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "def preprocess_data(image_files, label_files):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Define ImageDataGenerator for data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    for image_file, label_file in zip(image_files, label_files):\n",
    "        # Resize images to a standardized input size\n",
    "        image = cv2.imread(os.path.join(images_path, image_file))\n",
    "        image = cv2.resize(image, (416, 416))\n",
    "        X.append(image)\n",
    "\n",
    "        # Convert annotations to YOLO format\n",
    "        with open(os.path.join(labels_path, label_file), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                x_center /= image.shape[1]\n",
    "                y_center /= image.shape[0]\n",
    "                width /= image.shape[1]\n",
    "                height /= image.shape[0]\n",
    "                y.append([class_id, x_center, y_center, width, height])\n",
    "\n",
    "    # Split the dataset into training, validation, and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_model(input_shape,num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    model = yolo_model(num_classes=1)  # Assuming a single class for vehicles\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint = ModelCheckpoint('yolo_model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=50,\n",
    "              batch_size=32,\n",
    "              callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
